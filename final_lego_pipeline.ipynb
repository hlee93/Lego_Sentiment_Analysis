{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9cb1703-b7f1-43bf-989d-9d5290aa1f53",
   "metadata": {},
   "source": [
    "# Lego Marketing Sentiment\n",
    "\n",
    "## <em>Using Sentiment Analysis to analyse consumer sentiment towards Lego marketing campaigns.</em>\n",
    "\n",
    "The libraries used for this project include:\n",
    "- Python v3.9.1\n",
    "- PySpark v3.4.0\n",
    "- Emoji\n",
    "- Instaloader (as example of getting individual Instagram posts)\n",
    "- Seaborn\n",
    "\n",
    "## Project Features\n",
    "\n",
    "- Ingestion of data using structured streaming dataframes\n",
    "- Logistic Regression classifier model for sentiment analysis\n",
    "- Sample Dashboard widget demo\n",
    "\n",
    "## Why Logistic Regression?\n",
    "\n",
    "- binary data classification (positive or negative)\n",
    "- Handles noisier data better\n",
    "- Fast, needs less computational resource\n",
    "\n",
    "\n",
    "> **PLEASE NOTE**\n",
    "> An official social media api was not used for the following reasons:\n",
    ">\n",
    "> - Twitter has changed the data available for free tier, so streaming tweets wasn't possible.\n",
    "> - Instagram and Facebook have a manual authorisation process which would not be completed before project due date.\n",
    ">\n",
    "> Thus, an Instagram comment dataset csv was created, and will be used to simulate streaming data.\n",
    "\n",
    "The training set for this project can be found here: [Sentiment401](http://help.sentiment140.com/for-students/])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3770634-56fa-4a76-ab7b-642270f2d89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "import pyspark.sql.types as tp\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.feature import StopWordsRemover, Word2Vec, RegexTokenizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col, udf, lit\n",
    "from pyspark.sql.functions import lower, countDistinct\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import shutil\n",
    "import re\n",
    "import operator\n",
    "import functools\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import instaloader\n",
    "from bs4 import BeautifulSoup\n",
    "import emoji\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nest_asyncio\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "#Below prevents errors when running spark sessions in jupyter\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fc490f-ba44-4656-84db-59fe2c4b62cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing spark session\n",
    "sc = SparkContext(appName=\"LegoSentiment\")\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa53eb8-6794-4389-be2b-0a3949064fc4",
   "metadata": {},
   "source": [
    "## Model Pipeline Definition, Training and Evaluation\n",
    "\n",
    "See Above for training dataset used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce5c20-0b7e-4be3-888f-af66a492c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define schemas for training and instagram post data\n",
    "train_schema = tp.StructType([\n",
    "    tp.StructField(name= 'polarity', dataType= tp.IntegerType(),  nullable= True),\n",
    "    tp.StructField(name= 'comment_id', dataType= tp.IntegerType(),   nullable= True),\n",
    "    tp.StructField(name= 'date', dataType= tp.TimestampType(),  nullable= True),\n",
    "    tp.StructField(name= 'query', dataType= tp.StringType(),   nullable= True),\n",
    "    tp.StructField(name= 'username', dataType= tp.StringType(),   nullable= True),\n",
    "    tp.StructField(name= 'comment', dataType= tp.StringType(),   nullable= True)                \n",
    "  ,\n",
    "])\n",
    "\n",
    "insta_schema = tp.StructType([\n",
    "    tp.StructField(name= 'id', dataType= tp.IntegerType(),  nullable= True),\n",
    "    tp.StructField(name= 'username', dataType= tp.StringType(),   nullable= True),\n",
    "    tp.StructField(name= 'comment', dataType= tp.StringType(),   nullable= True),\n",
    "    tp.StructField(name= 'comment_id', dataType= tp.IntegerType(),   nullable= True),\n",
    "    tp.StructField(name= 'profile_url', dataType= tp.StringType(),   nullable= True),\n",
    "    tp.StructField(name= 'comment_url', dataType= tp.StringType(),   nullable= True)                \n",
    "  ,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c62c55-78a2-47a3-a08c-0efcdd687195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training data\n",
    "training_data = spark.read.csv('C:/Users/hayle/Desktop/lego_post_data/sentiment_model_data/training_data.csv',schema = train_schema,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59712dbf-a8dc-4b05-a1d5-36c7683d178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the data and deal with null values\n",
    "df = training_data.na.fill('')\n",
    "df = df.na.fill(value=0)\n",
    "df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f301f1-5ed2-4744-bbe8-775c77071cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unneccessary colums and drop usernames to anonymise data\n",
    "df = df.drop('query')\n",
    "df = df.drop('username')\n",
    "df = df.drop('date')\n",
    "df.show(20)\n",
    "\n",
    "#How many entries in training data\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110cde3f-5ed1-4763-9e09-8dcd7e0e5200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split training data for training and testing\n",
    "(train_set, val_set, test_set) = df.randomSplit([0.98, 0.01, 0.01], seed = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c47418-94cb-4b86-a1f1-61a8bdde3389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define transformation pipeline for incoming data\n",
    "#split text into individual word tokens\n",
    "tokenizer = Tokenizer(inputCol=\"comment\", outputCol=\"words\")\n",
    "#increase memory efficiency and scalability using hashing\n",
    "hashtf = HashingTF(numFeatures=2**16, inputCol=\"words\", outputCol='tf')\n",
    "#Inverse Document Frequency, measure importance of word token in entry\n",
    "idf = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "#convert any categorical str vals to numerical for ML prep\n",
    "label_stringIdx = StringIndexer(inputCol = \"polarity\", outputCol = \"label\")\n",
    "#Define pipeline steps\n",
    "pipeline = Pipeline(stages=[tokenizer, hashtf, idf, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f52ebb-8db9-409f-b629-0279e9a59b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit training set data to pipeline processes     \n",
    "pipelineFit = pipeline.fit(train_set)\n",
    "print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c641c45f-90c7-4109-a648-9eeabd1a441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run pipeline process on train and val set\n",
    "train_df = pipelineFit.transform(train_set)\n",
    "val_df = pipelineFit.transform(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009df3f8-e635-4233-bde0-0bc7e4b510e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show transformed training set\n",
    "train_df.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbd1b4a-9342-4517-9ed6-963d8f70bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate and train logistic regression model\n",
    "lr = LogisticRegression(maxIter=100)\n",
    "lrModel = lr.fit(train_df)\n",
    "predictions = lrModel.transform(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a949e999-3cd2-4878-ab54-4f777abf6d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show results\n",
    "predictions.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da59d0e9-79e7-4561-8d80-6d83b52d00aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses Area Under the Curve (AUC). \n",
    "#Bigger the value, better the model is at distinguishing between categories\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472b067d-fdff-4623-8425-ccd1fc8e70c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate model accuracy\n",
    "accuracy = predictions.filter(predictions.label == predictions.prediction).count() / float(val_set.count())\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27755fde-03da-4475-ac8f-1409768d8139",
   "metadata": {},
   "source": [
    "## Ingestion, Transformation and Sentiment Analysis of Structured Streaming Instagram Comments\n",
    "\n",
    "Using an unbounded dataframe method, more fault tolerant and scalable than socket according to Spark docs\n",
    "\n",
    "> **NOTE** An instance of Instaloader was included to show how post data from Lego's Instagram page could be scraped.\n",
    "> Using Facebook Graph API with elevated permissions for business is recommended for production stability and legal reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4dd9fe-af33-4c57-918d-0af14a8b7670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instaloader instance, an example of how to scrape insta post information realtime.\n",
    "#Instagram will sometimes return a 401 if too many requests in a short time period, so not fault tolerant.\n",
    "instapost = instaloader.Instaloader()\n",
    "profile = instaloader.Profile.from_username(instapost.context,'lego')\n",
    "posts = profile.get_posts()\n",
    "count = 0\n",
    "post_list = []\n",
    "\n",
    "for post in posts:\n",
    "    if count < 3:\n",
    "        instapost.download_post(post, 'lego')\n",
    "        post_params = dict()\n",
    "        post_params['Url'] = post.url\n",
    "        post_params['Likes'] = post.likes\n",
    "        post_params['Caption'] = post.caption\n",
    "        post_params['Caption_Hashtags'] = post.caption_hashtags\n",
    "        count=count+1\n",
    "        time.sleep(5)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0a32a2-6fcc-4e3c-9a73-0c82cc3ab4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing of instagram comments\n",
    "def preprocess_sentence(text):\n",
    "    # remove html tags\n",
    "    text = BeautifulSoup(text.encode('utf8'), \"html.parser\").get_text()\n",
    "    # convert the text to lower case\n",
    "    text.lower()\n",
    "    # convert all urls to string \"URL\"\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', text)\n",
    "    # convert all @username to \"AT_USER\"\n",
    "    text = re.sub('@[^\\s]+', 'AT_USER', text)\n",
    "    # correct all multiple white spaces to a single white space\n",
    "    text = re.sub('[\\s]+', ' ', text)\n",
    "    # convert \"#topic\" to just \"topic\"\n",
    "    text = re.sub(r'#([^\\s]+)', r'\\1', text)\n",
    "    \n",
    "\n",
    "    # split emojis\n",
    "    text = emoji.get_emoji_regexp().split(text)\n",
    "    text = [substr.split() for substr in text]\n",
    "    text = \" \".join(functools.reduce(operator.concat, text))\n",
    "    # convert emojis to text\n",
    "    text = emoji.demojize(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaf4397-a38b-47cd-b5f1-06b96fd59e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create structured streaming dataframe\n",
    "insta_comment_folder = r'C:/Users/hayle/Desktop/lego_post_data/lego_insta_comments'\n",
    "insta_comments = spark.readStream.format('csv').schema(insta_schema).option('header', True).option('maxFilesPerTrigger', 1).load(insta_comment_folder)\n",
    "insta_comments.dropDuplicates(['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc422c3f-ba2f-4de6-9d07-c3560ce6e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "insta_comments.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcbd799-398e-408a-9be4-f5085c6862ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anonymise comments (GDPR) and drop useless columns\n",
    "df = insta_comments.drop('username').drop('profile_url')\n",
    "#Start dataframe streaming and save to memory\n",
    "query = df.writeStream.format('memory').queryName('temp').outputMode('append').start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d651d7-c740-488d-bee2-0d18256f2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Due to data restrictions, will simulate streaming conditions by dropping csv into folder 😭\n",
    "shutil.move('C:/Users/hayle/Desktop/lego_post_data/post_1.csv', 'C:/Users/hayle/Desktop/lego_post_data/lego_insta_comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c017fd-cae9-4685-b63a-edb67e966c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess comment in dataframe\n",
    "cleanUDF = udf(lambda x:preprocess_sentence(x),tp.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba5adf7-d935-42fb-a598-ca56e92a26d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check dataframe creation and data correctly processed.\n",
    "query_df = spark.sql(\"SELECT * FROM temp\")\n",
    "query_df = query_df.na.fill('').na.fill(value=0)\n",
    "query_df = query_df.withColumn(\"comment\",cleanUDF(col(\"comment\")))\n",
    "query_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c451d50b-9408-4a00-bc5d-7023f3dc6be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run transformation on data\n",
    "final_df = pipelineFit.transform(query_df)\n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817dc5f8-e125-441c-b4ae-fd8adb713d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run logistic regression model on data\n",
    "lego_pred = lrModel.transform(final_df)\n",
    "lego_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc65f09d-5219-4101-ad7b-16e66387cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lego_pred = lego_pred.withColumn('words',lego_pred.words.cast(tp.StringType()))\n",
    "lego_pred = lego_pred.withColumn('tf',lego_pred.tf.cast(tp.StringType()))\n",
    "lego_pred = lego_pred.withColumn('features',lego_pred.features.cast(tp.StringType()))\n",
    "#lego_pred = lego_pred.withColumn('rawPrediction',lego_pred.rawPrediction.cast(tp.StringType()))\n",
    "#lego_pred = lego_pred.withColumn('probability',lego_pred.probability.cast(tp.StringType()))\n",
    "#lego_pred = lego_pred.withColumn('prediction',lego_pred.prediction.cast(tp.StringType()))\n",
    "lego_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b65d01d-dd7f-4fbe-9e85-99ec2572055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = lego_pred.toPandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc34d46f-424f-4f5a-9300-14e78778b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "#simulate storing for later/historical data analysis\n",
    "lego_pred.write.csv('C:/Users/hayle/Desktop/lego_post_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f216a04-3792-4b42-9748-51ee1917d629",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['comment','prediction']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5633c72c-713a-4456-a0c0-cd2775b15ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metric = df.groupby('prediction').count()\n",
    "df_metric['sentiment'] = ['negative', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ebc19d-c8ba-4044-b96a-2a9e4bdc300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85073d9b-0ce0-4ca0-af0e-2d6bc8cf887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pie chart for dashboard\n",
    "palette_color = sns.color_palette('bright')\n",
    "labels = ['negative', 'postive']\n",
    "plt.pie(data=df_metric,x= 'comment', labels=labels, colors=palette_color, autopct='%.0f%%')\n",
    "plt.show()\n",
    "\n",
    "#Barchart for dashboard\n",
    "bars = sns.barplot(x='comment',y='sentiment', data=df_metric)\n",
    "bars.set(xlabel='comment count')\n",
    "bars"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
